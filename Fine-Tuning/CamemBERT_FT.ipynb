{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c5e7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import CamembertTokenizerFast, DataCollatorForTokenClassification, CamembertForTokenClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6433984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59900, 14758)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_json_safely(file_path):\n",
    "    try:\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    except:\n",
    "        try:\n",
    "            \n",
    "            data = []\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        \n",
    "                        data.append(json.loads(line.strip()))\n",
    "                    except:\n",
    "                        continue\n",
    "            return data\n",
    "        except:\n",
    "            \n",
    "            return pd.read_json(file_path, lines=True).to_dict('records')\n",
    "\n",
    "\n",
    "train_data = load_json_safely('./annotations/train_extended_bio_feb.json')\n",
    "test_data = load_json_safely('./annotations/val_extended_bio_feb.json')\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59900/59900 [00:08<00:00, 7473.38 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14758/14758 [00:01<00:00, 7633.24 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 59900/59900 [01:13<00:00, 815.40 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14758/14758 [00:19<00:00, 766.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict({\"tokens\": [item[\"tokens\"] for item in train_data],\n",
    "                                   \"ner_tags\": [item[\"tags\"] for item in train_data]})\n",
    "test_dataset = Dataset.from_dict({\"tokens\": [item[\"tokens\"] for item in test_data],\n",
    "                                  \"ner_tags\": [item[\"tags\"] for item in test_data]})\n",
    "\n",
    "\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "\n",
    "label_list = [\"O\", \"B-country\", \"I-country\", \"B-region\", \"I-region\", \"B-departement\", \"I-departement\", \"B-province\", \"I-province\", \"B-village\", \"I-village\"]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "def convert_tags_to_ids(examples):\n",
    "    examples[\"ner_tags\"] = [[label2id[tag] for tag in tags] for tags in examples[\"ner_tags\"]]\n",
    "    return examples\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(convert_tags_to_ids, batched=True)\n",
    "test_dataset = test_dataset.map(convert_tags_to_ids, batched=True)\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        is_split_into_words=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    batch_labels  = []\n",
    "    batch_offsets = []\n",
    "\n",
    "\n",
    "    for i, labels in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids      = tokenized.word_ids(batch_index=i)\n",
    "        offsets_i     = tokenized[\"offset_mapping\"][i]\n",
    "        label_ids, offs = [], []\n",
    "\n",
    "        prev_word_idx = None\n",
    "        for idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx is None:\n",
    "\n",
    "                label_ids.append(-100)\n",
    "                offs.append((None, None))\n",
    "            elif word_idx != prev_word_idx:\n",
    "\n",
    "                label_ids.append(labels[word_idx])\n",
    "                offs.append(offsets_i[idx])\n",
    "            else:\n",
    "\n",
    "                label_ids.append(-100)\n",
    "                offs.append((None, None))\n",
    "            prev_word_idx = word_idx\n",
    "\n",
    "        batch_labels.append(label_ids)\n",
    "        batch_offsets.append(offs)\n",
    "\n",
    "\n",
    "    tokenized[\"labels\"]       = batch_labels\n",
    "    tokenized[\"char_offsets\"] = batch_offsets\n",
    "\n",
    "\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0e608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CamembertForTokenClassification.from_pretrained(\"camembert-base\", num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0517f940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CamembertForTokenClassification(\n",
       "  (roberta): CamembertModel(\n",
       "    (embeddings): CamembertEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): CamembertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x CamembertLayer(\n",
       "          (attention): CamembertAttention(\n",
       "            (self): CamembertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): CamembertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CamembertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): CamembertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3412f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geler les embeddings\n",
    "for param in model.roberta.embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# #Geler les premi√®res couches du CamembertEncoder (par exemple, les 8 premi√®res sur 12)\n",
    "# for layer in model.roberta.encoder.layer[:-4]:  # Ne pas entra√Æner les 8 premi√®res couches\n",
    "#     for param in layer.parameters():\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bfe3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de param√®tres: 110,039,819\n",
      "Param√®tres entra√Ænables: 85,062,923\n",
      "Param√®tres gel√©s: 24,976,896\n",
      "Pourcentage entra√Ænable: 77.30%\n",
      "\n",
      "--- D√©tails par composant ---\n",
      "roberta: 85,054,464/110,031,360 param√®tres entra√Ænables\n",
      "dropout: 0/0 param√®tres entra√Ænables\n",
      "classifier: 8,459/8,459 param√®tres entra√Ænables\n"
     ]
    }
   ],
   "source": [
    "# Compter les param√®tres entra√Ænables vs gel√©s\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(f\"Total de param√®tres: {total_params:,}\")\n",
    "print(f\"Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "print(f\"Param√®tres gel√©s: {frozen_params:,}\")\n",
    "print(f\"Pourcentage entra√Ænable: {100 * trainable_params / total_params:.2f}%\")\n",
    "\n",
    "# D√©tails par composant\n",
    "print(\"\\n--- D√©tails par composant ---\")\n",
    "for name, module in model.named_children():\n",
    "    module_params = sum(p.numel() for p in module.parameters())\n",
    "    module_trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    print(f\"{name}: {module_trainable:,}/{module_params:,} param√®tres entra√Ænables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62720ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/stkgfs/stkgfs/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2016' max='131040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2016/131040 40:47 < 43:32:58, 0.82 it/s, Epoch 1.08/70]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.055543</td>\n",
       "      <td>0.254341</td>\n",
       "      <td>0.156014</td>\n",
       "      <td>0.193398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>0.867308</td>\n",
       "      <td>0.837670</td>\n",
       "      <td>0.852231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.888305</td>\n",
       "      <td>0.916525</td>\n",
       "      <td>0.902195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.938660</td>\n",
       "      <td>0.941978</td>\n",
       "      <td>0.940316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.934590</td>\n",
       "      <td>0.950933</td>\n",
       "      <td>0.942691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charles/stkgfs/stkgfs/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 50\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Initialiser le Trainer\u001b[39;00m\n\u001b[1;32m     40\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     41\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     42\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stkgfs/stkgfs/lib/python3.10/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stkgfs/stkgfs/lib/python3.10/site-packages/transformers/trainer.py:2393\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# D√©finir les arguments d'entra√Ænement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/data/charles/agile/camembert-ner-finetuned\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=70,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps = 100,\n",
    "    #\n",
    "    do_train=True,\n",
    "    do_predict=True,\n",
    "    save_total_limit=100,\n",
    "    push_to_hub=False,\n",
    "    #metric_for_best_model=\"eval_loss\",\n",
    "    #load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour calculer les m√©triques\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [[id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "                        for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    results = classification_report(true_labels, true_predictions, output_dict=True)\n",
    "    return {\n",
    "        \"precision\": results[\"micro avg\"][\"precision\"],\n",
    "        \"recall\": results[\"micro avg\"][\"recall\"],\n",
    "        \"f1\": results[\"micro avg\"][\"f1-score\"],\n",
    "    }\n",
    "\n",
    "# Initialiser le Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae1c6a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.004938560537993908,\n",
       " 'eval_precision': 0.9345902626580812,\n",
       " 'eval_recall': 0.950933257918552,\n",
       " 'eval_f1': 0.9426909328785364}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b15cfda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11594/11594 [00:01<00:00, 7448.30 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11594/11594 [00:06<00:00, 1800.65 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import CamembertTokenizerFast, DataCollatorForTokenClassification, CamembertForTokenClassification, Trainer\n",
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "# Fonction pour charger les donn√©es JSON\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Charger les donn√©es de test\n",
    "test_data = load_json('./annotations/test_extended_bio_feb.json')\n",
    "\n",
    "# Convertir en format Dataset\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"tokens\": [item[\"tokens\"] for item in test_data],\n",
    "    \"ner_tags\": [item[\"tags\"] for item in test_data]\n",
    "})\n",
    "\n",
    "# Initialiser le tokenizer\n",
    "tokenizer = CamembertTokenizerFast.from_pretrained(\"camembert-base\")\n",
    "\n",
    "# D√©finir la liste des √©tiquettes et cr√©er les mappings label <-> id\n",
    "label_list = [\"O\", \"B-country\", \"I-country\", \"B-region\", \"I-region\", \"B-departement\", \"I-departement\", \"B-province\", \"I-province\", \"B-village\", \"I-village\"]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Fonction pour convertir les √©tiquettes en IDs\n",
    "def convert_tags_to_ids(examples):\n",
    "    examples[\"ner_tags\"] = [[label2id[tag] for tag in tags] for tags in examples[\"ner_tags\"]]\n",
    "    return examples\n",
    "\n",
    "# Appliquer la conversion sur le dataset de test\n",
    "test_dataset = test_dataset.map(convert_tags_to_ids, batched=True)\n",
    "\n",
    "# Fonction pour tokeniser les entr√©es et aligner les √©tiquettes\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        is_split_into_words=True,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Ignorer les tokens sp√©ciaux\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])  # Nouveau mot\n",
    "            else:\n",
    "                label_ids.append(-100)  # M√™me mot, ignorer\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Appliquer la tokenisation et l'alignement des √©tiquettes\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Charger le mod√®le fine-tun√©\n",
    "model = CamembertForTokenClassification.from_pretrained(\"/data/charles/agile/camembert-ner-finetuned/checkpoint-2000\", num_labels=len(label_list))\n",
    "\n",
    "# Initialiser le Trainer sans entra√Ænement, uniquement pour l'√©valuation\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer),\n",
    ")\n",
    "\n",
    "# Effectuer les pr√©dictions sur le jeu de test\n",
    "predictions, labels, _ = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Convertir les IDs en √©tiquettes\n",
    "true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "true_predictions = [[id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "                    for prediction, label in zip(predictions, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ab1e98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.97      0.99      0.98      4648\n",
      " departement       0.95      0.96      0.95      6744\n",
      "    province       0.91      0.92      0.91       541\n",
      "      region       0.98      0.99      0.99      1433\n",
      "     village       0.84      0.81      0.82      3236\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     16602\n",
      "   macro avg       0.93      0.93      0.93     16602\n",
      "weighted avg       0.94      0.94      0.94     16602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher le rapport de classification\n",
    "print(classification_report(true_labels, true_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1abd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stkgfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
